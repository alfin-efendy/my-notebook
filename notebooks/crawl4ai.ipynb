{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: crawl4ai in /opt/conda/lib/python3.11/site-packages (0.3.5)\n",
      "Requirement already satisfied: nest_asyncio in /opt/conda/lib/python3.11/site-packages (1.5.8)\n",
      "Requirement already satisfied: playwright in /opt/conda/lib/python3.11/site-packages (1.47.0)\n",
      "Requirement already satisfied: aiosqlite==0.20.0 in /opt/conda/lib/python3.11/site-packages (from crawl4ai) (0.20.0)\n",
      "Requirement already satisfied: html2text==2024.2.26 in /opt/conda/lib/python3.11/site-packages (from crawl4ai) (2024.2.26)\n",
      "Requirement already satisfied: lxml==5.3.0 in /opt/conda/lib/python3.11/site-packages (from crawl4ai) (5.3.0)\n",
      "Requirement already satisfied: litellm==1.48.0 in /opt/conda/lib/python3.11/site-packages (from crawl4ai) (1.48.0)\n",
      "Requirement already satisfied: numpy<2.1.1,>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from crawl4ai) (2.1.0)\n",
      "Requirement already satisfied: pillow==10.4.0 in /opt/conda/lib/python3.11/site-packages (from crawl4ai) (10.4.0)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /opt/conda/lib/python3.11/site-packages (from crawl4ai) (1.0.1)\n",
      "Requirement already satisfied: requests<2.32.3,>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from crawl4ai) (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in /opt/conda/lib/python3.11/site-packages (from crawl4ai) (4.12.3)\n",
      "Requirement already satisfied: greenlet==3.0.3 in /opt/conda/lib/python3.11/site-packages (from playwright) (3.0.3)\n",
      "Requirement already satisfied: pyee==12.0.0 in /opt/conda/lib/python3.11/site-packages (from playwright) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.11/site-packages (from aiosqlite==0.20.0->crawl4ai) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4==4.12.3->crawl4ai) (2.5)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from litellm==1.48.0->crawl4ai) (3.10.10)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from litellm==1.48.0->crawl4ai) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.48.0->crawl4ai) (6.8.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/conda/lib/python3.11/site-packages (from litellm==1.48.0->crawl4ai) (3.1.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.48.0->crawl4ai) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.45.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.48.0->crawl4ai) (1.51.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.48.0->crawl4ai) (2.9.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.48.0->crawl4ai) (0.8.0)\n",
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.11/site-packages (from litellm==1.48.0->crawl4ai) (0.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<2.32.3,>=2.26.0->crawl4ai) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<2.32.3,>=2.26.0->crawl4ai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<2.32.3,>=2.26.0->crawl4ai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<2.32.3,>=2.26.0->crawl4ai) (2023.7.22)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm==1.48.0->crawl4ai) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.48.0->crawl4ai) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.48.0->crawl4ai) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.48.0->crawl4ai) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.48.0->crawl4ai) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.48.0->crawl4ai) (0.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.45.0->litellm==1.48.0->crawl4ai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.45.0->litellm==1.48.0->crawl4ai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.45.0->litellm==1.48.0->crawl4ai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.45.0->litellm==1.48.0->crawl4ai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai>=1.45.0->litellm==1.48.0->crawl4ai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai>=1.45.0->litellm==1.48.0->crawl4ai) (4.66.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->litellm==1.48.0->crawl4ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->litellm==1.48.0->crawl4ai) (2.23.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm==1.48.0->crawl4ai) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->litellm==1.48.0->crawl4ai) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->litellm==1.48.0->crawl4ai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->litellm==1.48.0->crawl4ai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->litellm==1.48.0->crawl4ai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->litellm==1.48.0->crawl4ai) (1.15.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.11/site-packages (from tokenizers->litellm==1.48.0->crawl4ai) (0.25.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.45.0->litellm==1.48.0->crawl4ai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.45.0->litellm==1.48.0->crawl4ai) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.48.0->crawl4ai) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.48.0->crawl4ai) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.48.0->crawl4ai) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.48.0->crawl4ai) (6.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->litellm==1.48.0->crawl4ai) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Playwright Host validation warning: \n",
      "╔══════════════════════════════════════════════════════╗\n",
      "║ Host system is missing dependencies to run browsers. ║\n",
      "║ Please install them with the following command:      ║\n",
      "║                                                      ║\n",
      "║     sudo playwright install-deps                     ║\n",
      "║                                                      ║\n",
      "║ Alternatively, use apt:                              ║\n",
      "║     sudo apt-get install libnss3\\                    ║\n",
      "║         libnspr4\\                                    ║\n",
      "║         libatk1.0-0\\                                 ║\n",
      "║         libatk-bridge2.0-0\\                          ║\n",
      "║         libatspi2.0-0\\                               ║\n",
      "║         libxcomposite1\\                              ║\n",
      "║         libxdamage1                                  ║\n",
      "║                                                      ║\n",
      "║ <3 Playwright Team                                   ║\n",
      "╚══════════════════════════════════════════════════════╝\n",
      "    at validateDependenciesLinux (/opt/conda/lib/python3.11/site-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
      "    at async Registry._validateHostRequirements (/opt/conda/lib/python3.11/site-packages/playwright/driver/package/lib/server/registry/index.js:626:43)\n",
      "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/opt/conda/lib/python3.11/site-packages/playwright/driver/package/lib/server/registry/index.js:724:7)\n",
      "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/opt/conda/lib/python3.11/site-packages/playwright/driver/package/lib/server/registry/index.js:713:43)\n",
      "    at async t.<anonymous> (/opt/conda/lib/python3.11/site-packages/playwright/driver/package/lib/cli/program.js:119:7)\n"
     ]
    }
   ],
   "source": [
    "%pip install crawl4ai\n",
    "!python -m playwright install chromium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] 🚀 Initializing LocalSeleniumCrawlerStrategy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/ast.py:50: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  return compile(source, filename, mode, flags,\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/opt/conda/lib/python3.11/site-packages/pygments/regexopt.py:77: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: Service /home/jovyan/.cache/selenium/chromedriver/linux64/129.0.6668.100/chromedriver unexpectedly exited. Status code was: 127\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrawl4ai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebCrawler\n\u001b[0;32m----> 3\u001b[0m crawler \u001b[38;5;241m=\u001b[39m \u001b[43mWebCrawler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m result \u001b[38;5;241m=\u001b[39m crawler\u001b[38;5;241m.\u001b[39mrun(url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.nbcnews.com/business\u001b[39m\u001b[38;5;124m\"\u001b[39m, css_selector\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle.tease-card\u001b[39m\u001b[38;5;124m\"\u001b[39m, bypass_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mextracted_content)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/crawl4ai/web_crawler.py:20\u001b[0m, in \u001b[0;36mWebCrawler.__init__\u001b[0;34m(self, crawler_strategy, always_by_pass_cache, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, crawler_strategy: CrawlerStrategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, always_by_pass_cache: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrawler_strategy \u001b[38;5;241m=\u001b[39m crawler_strategy \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mLocalSeleniumCrawlerStrategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malways_by_pass_cache \u001b[38;5;241m=\u001b[39m always_by_pass_cache\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrawl4ai_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(Path\u001b[38;5;241m.\u001b[39mhome(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.crawl4ai\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/crawl4ai/crawler_strategy.py:149\u001b[0m, in \u001b[0;36mLocalSeleniumCrawlerStrategy.__init__\u001b[0;34m(self, use_cached_html, js_code, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# chromedriver_autoinstaller.install()\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# import chromedriver_autoinstaller\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# crawl4ai_folder = os.path.join(Path.home(), \".crawl4ai\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Use selenium-manager (built into Selenium 4.10.0+)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m Service()\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_driver_created\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcookies\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/selenium/webdriver/chromium/webdriver.py:55\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     52\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m finder\u001b[38;5;241m.\u001b[39mget_driver_path()\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[1;32m     58\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[1;32m     59\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/selenium/webdriver/common/service.py:105\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_process_still_running\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connectable():\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/selenium/webdriver/common/service.py:118\u001b[0m, in \u001b[0;36mService.assert_process_still_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mService \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unexpectedly exited. Status code was: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: Service /home/jovyan/.cache/selenium/chromedriver/linux64/129.0.6668.100/chromedriver unexpectedly exited. Status code was: 127\n"
     ]
    }
   ],
   "source": [
    "from crawl4ai import WebCrawler\n",
    "\n",
    "crawler = WebCrawler(verbose=True)\n",
    "result = crawler.run(url=\"https://www.nbcnews.com/business\", css_selector=\"article.tease-card\", bypass_cache=True)\n",
    "print(result.extracted_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
